{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "054376b4-29cb-4c7b-ae8a-b58d62c3c8e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T23:32:41.254948Z",
     "iopub.status.busy": "2024-12-17T23:32:41.254051Z",
     "iopub.status.idle": "2024-12-17T23:59:11.291646Z",
     "shell.execute_reply": "2024-12-17T23:59:11.290880Z",
     "shell.execute_reply.started": "2024-12-17T23:32:41.254910Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, Train Loss: 75.3947, Val Loss: 5.3133\n",
      "Epoch 2/8, Train Loss: 0.4976, Val Loss: 0.8816\n",
      "Epoch 3/8, Train Loss: 0.2933, Val Loss: 0.5761\n",
      "Epoch 4/8, Train Loss: 0.2073, Val Loss: 0.8307\n",
      "Epoch 5/8, Train Loss: 0.1712, Val Loss: 0.5920\n",
      "Epoch 6/8, Train Loss: 0.1415, Val Loss: 0.6308\n",
      "Epoch 7/8, Train Loss: 0.1368, Val Loss: 0.4697\n",
      "Epoch 8/8, Train Loss: 0.1398, Val Loss: 0.4917\n",
      "Test Loss: 0.5527\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "data_path = '/home/jupyter/datasphere/project/new_sorted/new_sorted'\n",
    "data = pd.read_csv('preprocessed_data.csv')\n",
    "data.drop(columns=[\"Unnamed: 0\", \"link\", \"photos\", 'is_auction'], inplace=True)\n",
    "data['is_complete'] = data['is_complete'].replace({'True': 1, 'False': 0, '0.0': 0, '1.0': 1})\n",
    "data['is_complete'] = data['is_complete'].astype(float)\n",
    "data['price'] = np.log1p(data['price'])\n",
    "\n",
    "train_df, temp_df = train_test_split(data, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Создаем кастомный Dataset\n",
    "class HouseDataset(Dataset):\n",
    "    def __init__(self, dataframe, data_path, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        tabular_data = row.drop(['id', 'price']).values.astype(np.float32) \n",
    "        price = np.float32(row['price'])  \n",
    "\n",
    "        folder_path = os.path.join(self.data_path, str(int(row['id'])))\n",
    "        images = []\n",
    "        for img_name in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, img_name)\n",
    "            if os.path.isfile(img_path) and img_name.lower().endswith(('png', 'jpg', 'jpeg')): \n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                images.append(image)\n",
    "\n",
    "        if len(images) == 0:\n",
    "            raise ValueError(f\"No valid images found in folder {folder_path}\") \n",
    "\n",
    "        images = torch.stack(images) \n",
    "        return images, tabular_data, price\n",
    "\n",
    "\n",
    "\n",
    "# Преобразования для изображений\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = HouseDataset(train_df, data_path, transform=image_transforms)\n",
    "val_dataset = HouseDataset(val_df, data_path, transform=image_transforms)\n",
    "test_dataset = HouseDataset(test_df, data_path, transform=image_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Модель для обработки изображений\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, tabular_input_size):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.image_model = models.mobilenet_v3_large(pretrained=True)\n",
    "        self.image_model.classifier = nn.Sequential(\n",
    "            nn.Linear(self.image_model.classifier[0].in_features, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.tabular_model = nn.Sequential(\n",
    "            nn.Linear(tabular_input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256 + 64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, images, tabular_data):\n",
    "        batch_size, num_images, C, H, W = images.size()\n",
    "        images = images.view(-1, C, H, W) \n",
    "        image_features = self.image_model(images)\n",
    "        image_features = image_features.view(batch_size, num_images, -1).mean(1)  # усредняем по картинкам\n",
    "        tabular_features = self.tabular_model(tabular_data)\n",
    "        combined = torch.cat([image_features, tabular_features], dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output\n",
    "\n",
    "num_tabular_features = train_df.shape[1] - 2 \n",
    "model = CombinedModel(num_tabular_features).to('cuda')\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Функция обучения\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=8):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for images, tabular_data, targets in train_loader:\n",
    "            images, tabular_data, targets = images.to('cuda'), tabular_data.to('cuda'), targets.to('cuda')\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, tabular_data)\n",
    "            loss = criterion(outputs.squeeze(), targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        val_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, tabular_data, targets in val_loader:\n",
    "                images, tabular_data, targets = images.to('cuda'), tabular_data.to('cuda'), targets.to('cuda')\n",
    "                outputs = model(images, tabular_data)\n",
    "                loss = criterion(outputs.squeeze(), targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}\")\n",
    "\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=8)\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for images, tabular_data, targets in test_loader:\n",
    "        images, tabular_data, targets = images.to('cuda'), tabular_data.to('cuda'), targets.to('cuda')\n",
    "        outputs = model(images, tabular_data)\n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "print(f\"Test Loss: {test_loss/len(test_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dc59cfb-160c-4943-a084-0d881d8be65f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T00:13:49.318080Z",
     "iopub.status.busy": "2024-12-18T00:13:49.316944Z",
     "iopub.status.idle": "2024-12-18T00:14:09.042556Z",
     "shell.execute_reply": "2024-12-18T00:14:09.041741Z",
     "shell.execute_reply.started": "2024-12-18T00:13:49.318037Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSLE: 0.0013\n",
      "Test MAE: 0.5419\n",
      "Sample predictions (log prices):\n",
      "True values (log): [18.865751, 17.588272, 16.852491, 18.603003, 16.1593, 16.296242, 17.529083, 18.033195, 15.935886, 16.29205]\n",
      "Predicted values (log): [array([17.726133], dtype=float32), array([17.673765], dtype=float32), array([16.90988], dtype=float32), array([19.279734], dtype=float32), array([16.628782], dtype=float32), array([17.376747], dtype=float32), array([18.088667], dtype=float32), array([18.041325], dtype=float32), array([16.897636], dtype=float32), array([18.024426], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_true_list, y_pred_list = [], []\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tabular_features, images, labels in test_loader:\n",
    "        tabular_features, images, labels = tabular_features.to(device), images.to(device), labels.to(device)\n",
    "        outputs = model(tabular_features, images)\n",
    "        y_true_list.extend(labels.cpu().numpy()) \n",
    "        y_pred_list.extend(torch.clamp(outputs, min=0).cpu().numpy()) \n",
    "\n",
    "# Метрики на логарифмах\n",
    "msle = mean_squared_log_error(y_true_list, y_pred_list)\n",
    "mae = mean_absolute_error(y_true_list, y_pred_list)\n",
    "\n",
    "print(f\"Test MSLE: {msle:.4f}\")\n",
    "print(f\"Test MAE: {mae:.4f}\")\n",
    "\n",
    "print(\"Sample predictions (log prices):\")\n",
    "print(f\"True values (log): {y_true_list[:10]}\")\n",
    "print(f\"Predicted values (log): {y_pred_list[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7e9722-daca-4fd2-a0b9-9c3e39d9e27e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
